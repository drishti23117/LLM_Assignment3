{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "734c089e-62d4-4732-846b-27594d83bb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arunb/anaconda3/envs/project1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 16:59:35.682105: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730739575.695371  554627 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730739575.699332  554627 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-04 16:59:35.715480: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-level accuracy of the pre-trained model: 0.6733\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\").to(device)\n",
    "\n",
    "# Set pad token if not set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token if tokenizer.eos_token else tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# Load test dataset with labels\n",
    "test_dataset = load_dataset(\n",
    "    'csv', \n",
    "    data_files='test_samples.csv', \n",
    "    column_names=['premise', 'hypothesis', 'label'],  # Include the label column\n",
    "    split='train'\n",
    ")\n",
    "\n",
    "# Map string labels to integers\n",
    "label_mapping = {label: idx for idx, label in enumerate(set(test_dataset['label']))}\n",
    "encoded_labels = [label_mapping[label] for label in test_dataset['label']]\n",
    "\n",
    "# Tokenize the test dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['premise'],\n",
    "        examples['hypothesis'],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_data, labels):\n",
    "        self.input_ids = tokenized_data['input_ids']\n",
    "        self.attention_mask = tokenized_data['attention_mask']\n",
    "        self.labels = labels  # Add this to capture the numeric labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx]),\n",
    "            'attention_mask': torch.tensor(self.attention_mask[idx]),\n",
    "            'labels': torch.tensor(self.labels[idx]),  # Store numeric labels\n",
    "        }\n",
    "\n",
    "# Create test DataLoader\n",
    "custom_test_dataset = CustomDataset(tokenized_test, encoded_labels)\n",
    "test_dataloader = DataLoader(custom_test_dataset, batch_size=1)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    return (predictions == labels).sum().item()\n",
    "\n",
    "# Evaluate pre-trained model\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Get logits from the model output\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Get the most likely class predictions\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        # Compare predictions with actual labels\n",
    "        total_correct += calculate_accuracy(predictions, labels)\n",
    "        total_samples += labels.size(0)  # Count total samples\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = total_correct / total_samples\n",
    "print(f\"Token-level accuracy of the pre-trained model: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d434d709-3e21-462e-8761-92d22917b0f8",
   "metadata": {},
   "source": [
    "Fine Tuned Models Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6d11a38-79fa-40bd-b5bd-a076f3503636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-level accuracy of the pre-trained model: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Load fine-tuned tokenizer and model from the specified directory\n",
    "model_directory = \"phi2-finetuned-epoch-1\"  # Update this path to your model's directory\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_directory)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_directory).to(device)\n",
    "\n",
    "# Set pad token if not set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token if tokenizer.eos_token else tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# Load test dataset with labels\n",
    "test_dataset = load_dataset(\n",
    "    'csv', \n",
    "    data_files='test_samples.csv', \n",
    "    column_names=['premise', 'hypothesis', 'label'],  # Include the label column\n",
    "    split='train'\n",
    ")\n",
    "\n",
    "# Map string labels to integers\n",
    "label_mapping = {label: idx for idx, label in enumerate(set(test_dataset['label']))}\n",
    "encoded_labels = [label_mapping[label] for label in test_dataset['label']]\n",
    "\n",
    "# Tokenize the test dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['premise'],\n",
    "        examples['hypothesis'],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_data, labels):\n",
    "        self.input_ids = tokenized_data['input_ids']\n",
    "        self.attention_mask = tokenized_data['attention_mask']\n",
    "        self.labels = labels  # Add this to capture the numeric labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx]),\n",
    "            'attention_mask': torch.tensor(self.attention_mask[idx]),\n",
    "            'labels': torch.tensor(self.labels[idx]),  # Store numeric labels\n",
    "        }\n",
    "\n",
    "# Create test DataLoader\n",
    "custom_test_dataset = CustomDataset(tokenized_test, encoded_labels)\n",
    "test_dataloader = DataLoader(custom_test_dataset, batch_size=1)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    return (predictions == labels).sum().item()\n",
    "\n",
    "# Evaluate pre-trained model\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Get logits from the model output\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Get the most likely class predictions\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        # Compare predictions with actual labels\n",
    "        total_correct += calculate_accuracy(predictions, labels)\n",
    "        total_samples += labels.size(0)  # Count total samples\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = total_correct / total_samples\n",
    "print(f\"Token-level accuracy of the pre-trained model: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2752317e-a1dd-45de-9660-34670faf57d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.88s/it]\n",
      "Map: 100%|███████████████████████████| 101/101 [00:00<00:00, 3858.82 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-level accuracy of the fine-tuned model: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Load fine-tuned tokenizer and model from the specified directory\n",
    "model_directory = \"phi2-finetuned-epoch-2\"  # Update this path to your model's directory\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_directory)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_directory).to(device)\n",
    "\n",
    "# Set pad token if not set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token if tokenizer.eos_token else tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# Load test dataset with labels\n",
    "test_dataset = load_dataset(\n",
    "    'csv', \n",
    "    data_files='test_samples.csv', \n",
    "    column_names=['premise', 'hypothesis', 'label'],  # Include the label column\n",
    "    split='train'\n",
    ")\n",
    "\n",
    "# Map string labels to integers\n",
    "label_mapping = {label: idx for idx, label in enumerate(set(test_dataset['label']))}\n",
    "encoded_labels = [label_mapping[label] for label in test_dataset['label']]\n",
    "\n",
    "# Tokenize the test dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['premise'],\n",
    "        examples['hypothesis'],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_data, labels):\n",
    "        self.input_ids = tokenized_data['input_ids']\n",
    "        self.attention_mask = tokenized_data['attention_mask']\n",
    "        self.labels = labels  # Add this to capture the numeric labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx]),\n",
    "            'attention_mask': torch.tensor(self.attention_mask[idx]),\n",
    "            'labels': torch.tensor(self.labels[idx]),  # Store numeric labels\n",
    "        }\n",
    "\n",
    "# Create test DataLoader\n",
    "custom_test_dataset = CustomDataset(tokenized_test, encoded_labels)\n",
    "test_dataloader = DataLoader(custom_test_dataset, batch_size=1)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    return (predictions == labels).sum().item()\n",
    "\n",
    "# Evaluate fine-tuned model\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Get logits from the model output\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Get the most likely class predictions\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        # Compare predictions with actual labels\n",
    "        total_correct += calculate_accuracy(predictions, labels)\n",
    "        total_samples += labels.size(0)  # Count total samples\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = total_correct / total_samples\n",
    "print(f\"Token-level accuracy of the fine-tuned model: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "096e4f10-0144-42e5-9605-be3839324018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.83s/it]\n",
      "Map: 100%|███████████████████████████| 101/101 [00:00<00:00, 3169.06 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-level accuracy of the fine-tuned model: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Load fine-tuned tokenizer and model from the specified directory\n",
    "model_directory = \"phi2-finetuned-epoch-3\"  # Update this path to your model's directory\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_directory)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_directory).to(device)\n",
    "\n",
    "# Set pad token if not set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token if tokenizer.eos_token else tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# Load test dataset with labels\n",
    "test_dataset = load_dataset(\n",
    "    'csv', \n",
    "    data_files='test_samples.csv', \n",
    "    column_names=['premise', 'hypothesis', 'label'],  # Include the label column\n",
    "    split='train'\n",
    ")\n",
    "\n",
    "# Map string labels to integers\n",
    "label_mapping = {label: idx for idx, label in enumerate(set(test_dataset['label']))}\n",
    "encoded_labels = [label_mapping[label] for label in test_dataset['label']]\n",
    "\n",
    "# Tokenize the test dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['premise'],\n",
    "        examples['hypothesis'],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_data, labels):\n",
    "        self.input_ids = tokenized_data['input_ids']\n",
    "        self.attention_mask = tokenized_data['attention_mask']\n",
    "        self.labels = labels  # Add this to capture the numeric labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx]),\n",
    "            'attention_mask': torch.tensor(self.attention_mask[idx]),\n",
    "            'labels': torch.tensor(self.labels[idx]),  # Store numeric labels\n",
    "        }\n",
    "\n",
    "# Create test DataLoader\n",
    "custom_test_dataset = CustomDataset(tokenized_test, encoded_labels)\n",
    "test_dataloader = DataLoader(custom_test_dataset, batch_size=1)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    return (predictions == labels).sum().item()\n",
    "\n",
    "# Evaluate fine-tuned model\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Get logits from the model output\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Get the most likely class predictions\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        # Compare predictions with actual labels\n",
    "        total_correct += calculate_accuracy(predictions, labels)\n",
    "        total_samples += labels.size(0)  # Count total samples\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = total_correct / total_samples\n",
    "print(f\"Token-level accuracy of the fine-tuned model: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1c22ed6-e0e5-4ca1-84f9-4a196d931fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.83s/it]\n",
      "Map: 100%|███████████████████████████| 101/101 [00:00<00:00, 3492.60 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-level accuracy of the fine-tuned model: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Load fine-tuned tokenizer and model from the specified directory\n",
    "model_directory = \"phi2-finetuned-epoch-4\"  # Update this path to your model's directory\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_directory)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_directory).to(device)\n",
    "\n",
    "# Set pad token if not set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token if tokenizer.eos_token else tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# Load test dataset with labels\n",
    "test_dataset = load_dataset(\n",
    "    'csv', \n",
    "    data_files='test_samples.csv', \n",
    "    column_names=['premise', 'hypothesis', 'label'],  # Include the label column\n",
    "    split='train'\n",
    ")\n",
    "\n",
    "# Map string labels to integers\n",
    "label_mapping = {label: idx for idx, label in enumerate(set(test_dataset['label']))}\n",
    "encoded_labels = [label_mapping[label] for label in test_dataset['label']]\n",
    "\n",
    "# Tokenize the test dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['premise'],\n",
    "        examples['hypothesis'],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_data, labels):\n",
    "        self.input_ids = tokenized_data['input_ids']\n",
    "        self.attention_mask = tokenized_data['attention_mask']\n",
    "        self.labels = labels  # Add this to capture the numeric labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx]),\n",
    "            'attention_mask': torch.tensor(self.attention_mask[idx]),\n",
    "            'labels': torch.tensor(self.labels[idx]),  # Store numeric labels\n",
    "        }\n",
    "\n",
    "# Create test DataLoader\n",
    "custom_test_dataset = CustomDataset(tokenized_test, encoded_labels)\n",
    "test_dataloader = DataLoader(custom_test_dataset, batch_size=1)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    return (predictions == labels).sum().item()\n",
    "\n",
    "# Evaluate fine-tuned model\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Get logits from the model output\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Get the most likely class predictions\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        # Compare predictions with actual labels\n",
    "        total_correct += calculate_accuracy(predictions, labels)\n",
    "        total_samples += labels.size(0)  # Count total samples\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = total_correct / total_samples\n",
    "print(f\"Token-level accuracy of the fine-tuned model: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5cda8e-a407-4d78-9d70-cabbd335ae93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-level accuracy of the pre-trained model: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Load the tokenizer and model from the same directory\n",
    "model_directory = \"phi2-finetuned-epoch-5\"  # Update this to your model folder path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_directory)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_directory).to(device)\n",
    "\n",
    "# Set pad token if not set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token if tokenizer.eos_token else tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# Load test dataset with labels\n",
    "test_dataset = load_dataset(\n",
    "    'csv', \n",
    "    data_files='test_samples.csv', \n",
    "    column_names=['premise', 'hypothesis', 'label'],  # Include the label column\n",
    "    split='train'\n",
    ")\n",
    "\n",
    "# Map string labels to integers\n",
    "label_mapping = {label: idx for idx, label in enumerate(set(test_dataset['label']))}\n",
    "encoded_labels = [label_mapping[label] for label in test_dataset['label']]\n",
    "\n",
    "# Tokenize the test dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['premise'],\n",
    "        examples['hypothesis'],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_data, labels):\n",
    "        self.input_ids = tokenized_data['input_ids']\n",
    "        self.attention_mask = tokenized_data['attention_mask']\n",
    "        self.labels = labels  # Add this to capture the numeric labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx]),\n",
    "            'attention_mask': torch.tensor(self.attention_mask[idx]),\n",
    "            'labels': torch.tensor(self.labels[idx]),  # Store numeric labels\n",
    "        }\n",
    "\n",
    "# Create test DataLoader\n",
    "custom_test_dataset = CustomDataset(tokenized_test, encoded_labels)\n",
    "test_dataloader = DataLoader(custom_test_dataset, batch_size=1)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(predictions, labels):\n",
    "    return (predictions == labels).sum().item()\n",
    "\n",
    "# Evaluate pre-trained model\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Get logits from the model output\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Get the most likely class predictions for the last token\n",
    "        predictions = torch.argmax(logits[:, -1, :], dim=-1)\n",
    "\n",
    "        # Convert predicted token IDs to class labels\n",
    "        predicted_classes = predictions.cpu().numpy()\n",
    "        actual_classes = labels.cpu().numpy()\n",
    "\n",
    "        # Compare predictions with actual labels\n",
    "        total_correct += (predicted_classes == actual_classes).sum()\n",
    "        total_samples += actual_classes.size  # Count total samples\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = total_correct / total_samples\n",
    "print(f\"Token-level accuracy of the pre-trained model: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6298dc58-dc18-49a3-a800-b27e44adc218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [50256]\n",
      "Labels: [2]\n",
      "Logits: [[[ 6.014112    2.7832603  -3.4612164  ... -1.1376925  -1.1369531\n",
      "   -1.1378222 ]\n",
      "  [ 3.6340315   2.84673    -0.25915742 ... -1.5786233  -1.5770816\n",
      "   -1.5782006 ]\n",
      "  [ 8.899673    5.6947994   4.1239567  ... -1.1998765  -1.1994023\n",
      "   -1.2003493 ]\n",
      "  ...\n",
      "  [10.216738   10.579777   11.074715   ... -4.5852213  -4.586058\n",
      "   -4.586841  ]\n",
      "  [10.189975   10.670112   11.233218   ... -4.567991   -4.5688133\n",
      "   -4.5695624 ]\n",
      "  [10.1188     10.721686   11.641347   ... -4.5617695  -4.562585\n",
      "   -4.563337  ]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions:\", predictions.cpu().numpy())\n",
    "print(\"Labels:\", labels.cpu().numpy())\n",
    "print(\"Logits:\", logits.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "265fc170-06ab-49ab-adcc-f57b6b57f714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 50295\n",
      "Label Mapping: {'0': 0, '2': 1, '1': 2, 'label': 3}\n",
      "Token ID for Label 2: #\n",
      "Predicted Token ID: 50256\n",
      "Predicted Token: <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# Print the vocabulary and label mapping\n",
    "print(\"Vocabulary Size:\", len(tokenizer.get_vocab()))\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "# Check the token id of the label\n",
    "print(\"Token ID for Label 2:\", tokenizer.convert_ids_to_tokens(2))\n",
    "print(\"Predicted Token ID:\", predictions.item())\n",
    "print(\"Predicted Token:\", tokenizer.convert_ids_to_tokens(predictions.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ea8919-7b9f-4e4a-9558-1276ca3c43a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters in the model: 2798033920\n",
      "Number of parameters being fine-tuned: 18350080\n",
      "Percentage of parameters fine-tuned: 0.66%\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "# Calculate total and fine-tunable parameters\n",
    "total_params, trainable_params = count_parameters(model)\n",
    "print(f\"Total parameters in the model: {total_params}\")\n",
    "print(f\"Number of parameters being fine-tuned: {trainable_params}\")\n",
    "print(f\"Percentage of parameters fine-tuned: {100 * trainable_params / total_params:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1349473-6b31-4e80-9386-b2148c671f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project1)",
   "language": "python",
   "name": "project1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
